############################# Server Basics #############################

# The id of the broker. This must be set to a unique integer for each broker.
broker.id={{ BR_ID }}
{# listeners=PLAINTEXT://:9092,SSL://:9093 #}
listeners={% for li in KAFKA_LISTNERS -%}
  {{ li['type'] }}://:{{ li['port'] }}{{ "," if not loop.last else "" }}
{%- endfor %}

# Hostname and port the broker will advertise to producers and consumers. If not set, 
# it uses the value for "listeners" if configured.  Otherwise, it will use the value
# returned from java.net.InetAddress.getCanonicalHostName().
{# advertised.listeners=PLAINTEXT://kafka{{ BR_ID }}:9092,SSL://kafka{{ BR_ID }}:9093 #}
advertised.listeners={% for li in KAFKA_LISTNERS -%}
{{ li['type'] }}://kafka{{ BR_ID }}:{{ li['port'] }}{{ "," if not loop.last else "" }}
{%- endfor %}

{% if KAFKA_SASL is defined and KAFKA_SASL == "GSSAPI" %}
sasl.enabled.mechanisms=GSSAPI
sasl.kerberos.service.name=kafka
{% endif %}


{% if "SSL" or "SASL_SSL" in KAFKA_LISTNERS|map(attribute="type") %}

############################## SSL/TLS ###############################
 
#ssl.enabled.protocols=TLSv1.2,TLSv1.1,TLSv1
security.inter.broker.protocol=SSL
ssl.client.auth=required
ssl.protocols=TLSv1.2

# KeyStore Files - Broker 
ssl.truststore.location={{ KAFKA_HOME }}/config/{{ KAFKA_TS_FILE }}
ssl.truststore.password={{ KAFKA_TS_PASS }}
ssl.keystore.location={{ KAFKA_HOME }}/config/{{ KAFKA_KS_FILE }}
ssl.keystore.password={{ KAFKA_KS_PASS }}
ssl.key.password={{ KAFKA_KEY_PASS }}
{% endif %}

############################# Log Basics #############################

# A comma seperated list of directories under which to store log files
log.dirs={{ BR_LOG_DIR }}

# The default number of log partitions per topic. More partitions allow greater
# parallelism for consumption, but this will also result in more files across
# the brokers.
num.partitions=8
# we will have 3 brokers so the default replication factor should be 2 0r 3
default.replication.factor=3
# number of IRS to have in order to minimize data loss
min.insync.replicas=2

############################# Log Retention Policy #############################

# The minimum age of a log file to be eligible for deletion due to age
# delete data after 1 week
log.retention.hours=168

# The maximum size of a log segment file. When this size is reached a new log segment will be created.
log.segment.bytes=1073741824

# The interval at which log segments are checked to see if they can be deleted according
# to the retention policies
log.retention.check.interval.ms=300000

############################# Zookeeper #############################

# Zookeeper connection string (see zookeeper docs for details).
# This is a comma separated host:port pairs, each corresponding to a zk
# server. e.g. "127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002".
# You can also append an optional chroot string to the urls to specify the
# root directory for all kafka znodes.
zookeeper.connect={% for node in groups['zookeeper'] -%}
  zookeeper{{ hostvars[node]['ZK_ID'] }}{{
    ":2182" if ZK_SSL is defined and ZK_SSL is sameas true else ":2181"
  }}{{ "," if not loop.last else "/kafka" }}
{%- endfor %}

{% if ZK_SSL is defined and ZK_SSL is sameas true %}
# Properties for SSL Security between Zookeeper and Brokers
zookeeper.ssl.client.enable=true
zookeeper.ssl.protocol=TLSv1.2
zookeeper.clientCnxnSocket=org.apache.zookeeper.ClientCnxnSocketNetty
#zookeeper.set.acl=true
# KeyStore Files - Zookeeper 
zookeeper.ssl.truststore.location={{ KAFKA_HOME }}/config/{{ KAFKA_TS_FILE }}
zookeeper.ssl.truststore.password={{ KAFKA_TS_PASS }}
zookeeper.ssl.keystore.location={{ KAFKA_HOME }}/config/{{ KAFKA_KS_FILE }}
zookeeper.ssl.keystore.password={{ KAFKA_KS_PASS }}
{% endif %}

# Timeout in ms for connecting to zookeeper
zookeeper.connection.timeout.ms=6000
 
############################# Others #############################

# Switch to enable topic deletion or not, default value is false
delete.topic.enable=true
# Auto Create topics recommended to set as false in production
auto.create.topics.enable=true
